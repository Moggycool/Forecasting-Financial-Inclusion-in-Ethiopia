{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "2efb2461",
            "metadata": {},
            "source": [
                "# Task 3 — Event Impact Modeling (Ethiopia Financial Inclusion)\n",
                "\n",
                "This notebook is configured for your project paths:\n",
                "\n",
                "## Inputs (priority)\n",
                "- `data/processed/eda_enriched/events.csv`\n",
                "- `data/processed/eda_enriched/ethiopia_fi_unified_data__impact_links.csv`\n",
                "- `data/processed/eda_enriched/temporal_range__observations.csv`\n",
                "\n",
                "## Fallback input\n",
                "- `data/raw/ethiopia_fi_unified_data.csv` (only if processed files missing)\n",
                "\n",
                "## Outputs\n",
                "- `outputs/task_3/impact_links_summary.csv`\n",
                "- `outputs/task_3/event_effects_tidy.csv`\n",
                "- `outputs/task_3/event_indicator_association_matrix.csv`\n",
                "- `outputs/task_3/event_indicator_association_heatmap.png`\n",
                "\n",
                "## Modules\n",
                "- `fi.data_io`\n",
                "- `fi.impact_links`\n",
                "- `fi.event_effects`\n",
                "- `fi.association_matrix`\n",
                "- `fi.task3_validation` (optional validation cell)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f3cfc820",
            "metadata": {},
            "outputs": [],
            "source": [
                "from __future__ import annotations\n",
                "import numpy as np\n",
                "\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "ROOT = Path(\"..\").resolve()\n",
                "SRC_DIR = ROOT / \"src\"\n",
                "\n",
                "# Ensure the repo root is importable (so `import src...` works)\n",
                "if str(ROOT) not in sys.path:\n",
                "    sys.path.insert(0, str(ROOT))\n",
                "\n",
                "# Optional: also add src directly (lets you `import fi...` if you prefer)\n",
                "if str(SRC_DIR) not in sys.path:\n",
                "    sys.path.insert(0, str(SRC_DIR))\n",
                "\n",
                "print(\"ROOT:\", ROOT)\n",
                "print(\"sys.path[0:3]:\", sys.path[:3])\n",
                "\n",
                "\n",
                "\n",
                "import pandas as pd\n",
                "\n",
                "\n",
                "\n",
                "# --- imports from src/fi (package)\n",
                "from src.fi.data_io import load_csv, coerce_datetime\n",
                "from src.fi.impact_links import join_links_events, build_impact_links_summary\n",
                "from src.fi.event_effects import FINDEX_YEAR_GRID, effects_tidy\n",
                "from src.fi.association_matrix import build_association_matrix, plot_heatmap\n",
                "from src.fi.task3_validation import validate_telebirr_mm\n",
                "\n",
                "ROOT = Path('..').resolve()\n",
                "\n",
                "# Inputs (processed preferred)\n",
                "PROC_DIR = ROOT / 'data' / 'processed' / 'eda_enriched'\n",
                "EVENTS_PATH = PROC_DIR / 'events.csv'\n",
                "LINKS_PATH  = PROC_DIR / 'ethiopia_fi_unified_data__impact_links.csv'\n",
                "OBS_PATH    = PROC_DIR / 'temporal_range__observations.csv'\n",
                "\n",
                "# Fallback unified raw\n",
                "UNIFIED_RAW_PATH = ROOT / 'data' / 'raw' / 'ethiopia_fi_unified_data.csv'\n",
                "\n",
                "# Outputs\n",
                "OUT_DIR = ROOT / 'outputs' / 'task_3'\n",
                "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "KEY_INDICATORS = [\"ACC_OWNERSHIP\", \"ACC_MM_ACCOUNT\", \"USG_DIGITAL_PAYMENT\"]\n",
                "\n",
                "pd.set_option('display.width', 140)\n",
                "pd.set_option('display.max_columns', 80)\n",
                "\n",
                "print('ROOT:', ROOT)\n",
                "print('EVENTS_PATH:', EVENTS_PATH, 'exists=', EVENTS_PATH.exists())\n",
                "print('LINKS_PATH :', LINKS_PATH,  'exists=', LINKS_PATH.exists())\n",
                "print('OBS_PATH   :', OBS_PATH,    'exists=', OBS_PATH.exists())\n",
                "print('UNIFIED_RAW_PATH:', UNIFIED_RAW_PATH, 'exists=', UNIFIED_RAW_PATH.exists())\n",
                "print('OUT_DIR:', OUT_DIR)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "23498cd8",
            "metadata": {},
            "source": [
                "## 1) Load inputs (processed preferred; raw unified fallback)\n",
                "\n",
                "If any processed input is missing, we attempt to derive it from the raw unified file (requires `record_type` + relevant columns)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "74eb4238",
            "metadata": {},
            "outputs": [],
            "source": [
                "def _derive_from_unified(unified: pd.DataFrame):\n",
                "    \"\"\"Derive events, links, observations from unified if it contains record_type.\"\"\"\n",
                "    if 'record_type' not in unified.columns:\n",
                "        raise ValueError('Raw unified file is missing column: record_type')\n",
                "\n",
                "    events_u = unified.loc[unified['record_type'] == 'event'].copy() if (unified['record_type'] == 'event').any() else pd.DataFrame()\n",
                "    links_u  = unified.loc[unified['record_type'] == 'impact_link'].copy() if (unified['record_type'] == 'impact_link').any() else pd.DataFrame()\n",
                "    obs_u    = unified.loc[unified['record_type'] == 'observation'].copy() if (unified['record_type'] == 'observation').any() else pd.DataFrame()\n",
                "    return events_u, links_u, obs_u\n",
                "\n",
                "\n",
                "# Load processed inputs when present\n",
                "events = load_csv(str(EVENTS_PATH)) if EVENTS_PATH.exists() else pd.DataFrame()\n",
                "links  = load_csv(str(LINKS_PATH))  if LINKS_PATH.exists()  else pd.DataFrame()\n",
                "obs    = load_csv(str(OBS_PATH))    if OBS_PATH.exists()    else pd.DataFrame()\n",
                "\n",
                "obs_required_any = {\"indicator_code\", \"related_indicator\"}\n",
                "value_cols_any = {\"value_numeric\", \"value\", \"observed_value\"}\n",
                "date_cols_any = {\"observation_date\", \"date\", \"period_end\", \"period_start\", \"event_date\"}\n",
                "\n",
                "obs_is_observations = (\n",
                "    (not obs.empty)\n",
                "    and (len(obs_required_any.intersection(set(obs.columns))) > 0)\n",
                "    and (len(value_cols_any.intersection(set(obs.columns))) > 0)\n",
                "    and ((\"year\" in obs.columns) or (len(date_cols_any.intersection(set(obs.columns))) > 0))\n",
                ")\n",
                "\n",
                "if not obs_is_observations:\n",
                "    print(\"[task3-notebook] OBS_PATH is not an observations table; skipping Telebirr validation.\")\n",
                "    obs = pd.DataFrame()\n",
                "\n",
                "missing = {\n",
                "    'events': events.empty,\n",
                "    'links': links.empty,\n",
                "    'obs': obs.empty,\n",
                "}\n",
                "print('Missing (processed):', missing)\n",
                "\n",
                "# Fallback: derive missing parts from raw unified\n",
                "if any(missing.values()):\n",
                "    if not UNIFIED_RAW_PATH.exists():\n",
                "        raise FileNotFoundError(\n",
                "            'Some processed inputs are missing, and raw unified fallback was not found at: ' + str(UNIFIED_RAW_PATH)\n",
                "        )\n",
                "\n",
                "    unified_raw = pd.read_csv(UNIFIED_RAW_PATH)\n",
                "    print('Loaded raw unified:', unified_raw.shape)\n",
                "    if 'record_type' in unified_raw.columns:\n",
                "        display(unified_raw['record_type'].value_counts(dropna=False))\n",
                "\n",
                "    events_u, links_u, obs_u = _derive_from_unified(unified_raw)\n",
                "\n",
                "    if events.empty:\n",
                "        events = events_u\n",
                "    if links.empty:\n",
                "        links = links_u\n",
                "    if obs.empty:\n",
                "        obs = obs_u\n",
                "\n",
                "# Coerce dates if columns exist\n",
                "events = coerce_datetime(events, 'observation_date') if not events.empty else events\n",
                "obs    = coerce_datetime(obs, 'observation_date') if not obs.empty else obs\n",
                "\n",
                "print('events:', events.shape)\n",
                "print('links :', links.shape)\n",
                "print('obs   :', obs.shape)\n",
                "\n",
                "display(events.head(3) if not events.empty else pd.DataFrame({'note':['events is empty']}))\n",
                "display(links.head(3) if not links.empty else pd.DataFrame({'note':['links is empty']}))\n",
                "display(obs.head(3) if not obs.empty else pd.DataFrame({'note':['obs is empty']}))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b8cff5d7",
            "metadata": {},
            "source": [
                "## 2) Join impact links ↔ events and export `impact_links_summary.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "27c42999",
            "metadata": {},
            "outputs": [],
            "source": [
                "if links.empty:\n",
                "    raise ValueError(\n",
                "        'Impact links input is empty. Expected rows in: ' + str(LINKS_PATH) +\n",
                "        ' (or impact_link rows inside raw unified fallback).'\n",
                "    )\n",
                "if events.empty:\n",
                "    raise ValueError(\n",
                "        'Events input is empty. Expected rows in: ' + str(EVENTS_PATH) +\n",
                "        ' (or event rows inside raw unified fallback).'\n",
                "    )\n",
                "\n",
                "joined = join_links_events(links, events)\n",
                "summary = build_impact_links_summary(joined)\n",
                "\n",
                "summary_out = OUT_DIR / 'impact_links_summary.csv'\n",
                "summary.to_csv(summary_out, index=False)\n",
                "\n",
                "print('joined:', getattr(joined, 'shape', None))\n",
                "print('summary:', summary.shape)\n",
                "print('wrote:', summary_out)\n",
                "display(summary.head(15))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "54463841",
            "metadata": {},
            "source": [
                "## 3) Build event effect series on the Findex year grid and export `event_effects_tidy.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c0b5ce1e",
            "metadata": {},
            "outputs": [],
            "source": [
                "effects = effects_tidy(\n",
                "    df_summary=summary,\n",
                "    indicators=KEY_INDICATORS,\n",
                "    years=FINDEX_YEAR_GRID,\n",
                "    default_shape='ramp',\n",
                "    default_ramp_years=3.0\n",
                ")\n",
                "\n",
                "effects_out = OUT_DIR / 'event_effects_tidy.csv'\n",
                "effects.to_csv(effects_out, index=False)\n",
                "\n",
                "print('effects:', effects.shape)\n",
                "print('wrote:', effects_out)\n",
                "display(effects.head(30))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0bb7a63a",
            "metadata": {},
            "source": [
                "## 4) Build association matrix + heatmap\n",
                "\n",
                "Exports:\n",
                "- `event_indicator_association_matrix.csv`\n",
                "- `event_indicator_association_heatmap.png`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "10c2a896",
            "metadata": {},
            "outputs": [],
            "source": [
                "assoc = build_association_matrix(summary, KEY_INDICATORS)\n",
                "\n",
                "assoc_out = OUT_DIR / 'event_indicator_association_matrix.csv'\n",
                "heatmap_out = OUT_DIR / 'event_indicator_association_heatmap.png'\n",
                "\n",
                "assoc.to_csv(assoc_out, index=False)\n",
                "plot_heatmap(assoc, KEY_INDICATORS, str(heatmap_out))\n",
                "\n",
                "print('assoc:', assoc.shape)\n",
                "print('wrote:', assoc_out)\n",
                "print('wrote:', heatmap_out)\n",
                "display(assoc)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e16fed24",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "summary = pd.read_csv(\"../outputs/task_3/impact_links_summary.csv\")\n",
                "\n",
                "tele = summary[summary[\"event_name\"].astype(str).str.contains(\"telebirr\", case=False, na=False)]\n",
                "print(\"telebirr links:\", tele.shape)\n",
                "display(tele[[\"event_name\", \"indicator_code\", \"impact_magnitude_pp\"]])\n",
                "\n",
                "tele_mm = tele[tele[\"indicator_code\"].astype(str).str.upper().eq(\"ACC_MM_ACCOUNT\")]\n",
                "print(\"telebirr -> ACC_MM_ACCOUNT:\", tele_mm.shape)\n",
                "display(tele_mm[[\"event_name\", \"indicator_code\", \"impact_magnitude_pp\"]])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "441ece16",
            "metadata": {},
            "source": [
                "## 5) (Optional) Telebirr validation table\n",
                "\n",
                "If observations are present, we compute the Telebirr residual table. If not, we skip."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "58518631",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate Telebirr against all indicators it targets in the links summary\n",
                "if obs.empty:\n",
                "    print(\"Observations are empty; skipping Telebirr validation.\")\n",
                "else:\n",
                "    tele_mask = summary[\"event_name\"].astype(str).str.contains(\"telebirr\", case=False, na=False)\n",
                "    tele_targets = (\n",
                "        summary.loc[tele_mask, \"indicator_code\"]\n",
                "        .astype(str).str.strip()\n",
                "        .replace({\"\": float(\"nan\")})\n",
                "        .dropna()\n",
                "        .unique()\n",
                "        .tolist()\n",
                "    )\n",
                "    tele_targets = sorted(tele_targets)\n",
                "\n",
                "    print(\"Telebirr target indicators found in links:\", tele_targets)\n",
                "\n",
                "    frames = []\n",
                "    for ind in tele_targets:\n",
                "        frames.append(\n",
                "            validate_telebirr_mm(\n",
                "                obs,\n",
                "                summary,\n",
                "                year_a=2021,\n",
                "                year_b=2024,\n",
                "                target_indicator=ind,   # <-- key change\n",
                "                event_regex=\"telebirr\",\n",
                "            )\n",
                "        )\n",
                "\n",
                "    tele_val = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
                "    tele_out = OUT_DIR / \"telebirr_validation_table.csv\"\n",
                "    tele_val.to_csv(tele_out, index=False)\n",
                "    print(\"wrote:\", tele_out)\n",
                "    display(tele_val)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
